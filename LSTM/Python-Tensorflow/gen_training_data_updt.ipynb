{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T19:53:11.197003Z",
     "start_time": "2024-04-08T19:52:58.370204Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "\n",
    "# Import required libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps=24):\n",
    "    seq_indices = np.arange(0, X.shape[0] - time_steps + 1)\n",
    "    xs = [X[i:i+time_steps] for i in seq_indices]\n",
    "    ys = y[time_steps - 1:]\n",
    "    return xs, ys\n",
    "\n",
    "#this function won't work quite right--I think it checks the overall number of nas \n",
    "def filter_out_nas(list_of_dfs, max_consecutive_nas):\n",
    "    index_fil = []\n",
    "    for i, df in enumerate(list_of_dfs):\n",
    "        observed_column = df['observed']\n",
    "        # Check if there are any NAs at the beginning or end\n",
    "        first_na = observed_column.isna().values[0]\n",
    "        last_na = observed_column.isna().values[-1]\n",
    "        # Check if the number of consecutive NAs is within the threshold\n",
    "        num_consecutive_nas = np.sum(pd.isna(observed_column))\n",
    "        # use run length  \n",
    "        if num_consecutive_nas <= max_consecutive_nas and not first_na and not last_na:\n",
    "            index_fil.append(i)\n",
    "    return index_fil\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:50.290877Z",
     "start_time": "2024-04-08T21:57:50.285744Z"
    }
   },
   "id": "62adc08dff69eba2",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                   datetime  epa_pm25                           date  \\\n0       2021-04-15 22:00:00       6.0  2021-04-15 17:45:56.307692288   \n1       2021-04-15 23:00:00       6.0  2021-04-15 18:30:48.033333248   \n2       2021-04-16 00:00:00       6.0  2021-04-15 19:30:48.700000000   \n3       2021-04-16 01:00:00       4.0  2021-04-15 20:30:49.033333504   \n4       2021-04-16 02:00:00       5.0  2021-04-15 21:30:50.000000000   \n...                     ...       ...                            ...   \n876836  2022-01-01 03:00:00      16.2  2021-12-31 22:29:52.900000000   \n876837  2022-01-01 04:00:00      14.6  2021-12-31 23:29:53.900000000   \n876838  2022-01-01 05:00:00      14.8  2022-01-01 00:29:54.866666752   \n876839  2022-01-01 06:00:00      12.4  2022-01-01 01:29:55.800000000   \n876840  2022-01-01 07:00:00      21.0  2022-01-01 02:29:56.266666752   \n\n        temperature   humidity   pm25_cf_1  pm25_cf_1_b  pm25_cf_1_a  year  \\\n0         68.461538  26.307692    2.379615     2.279231     2.480000  2021   \n1         72.833333  25.000000  285.067167   267.172667   302.961667  2021   \n2         74.000000  25.666667  113.413167   107.516667   119.309667  2021   \n3         74.000000  26.000000   39.462500    37.122000    41.803000  2021   \n4         73.300000  25.800000   13.508167    12.777000    14.239333  2021   \n...             ...        ...         ...          ...          ...   ...   \n876836    57.566667  66.766667   16.765667    15.962667    17.568667  2022   \n876837    57.833333  65.933333   15.928833    15.129667    16.728000  2022   \n876838    58.666667  63.600000   14.932833    14.095667    15.770000  2022   \n876839    59.000000  62.000000   19.009333    18.067333    19.951333  2022   \n876840    57.900000  64.466667   39.604500    37.552667    41.656333  2022   \n\n        month        R2  calibrated  PearsonR       calv2  \\\n0           4  0.999831    4.811038  0.906382    4.811038   \n1           4  0.999831  121.371368  0.906382  121.371368   \n2           4  0.999831   63.850879  0.906382   63.850879   \n3           4  0.999831   26.366329  0.906382   26.366329   \n4           4  0.999831   11.425028  0.906382   11.425028   \n...       ...       ...         ...       ...         ...   \n876836      1  0.996783   12.006813  0.850793   12.006813   \n876837      1  0.996783   11.541068  0.850793   11.541068   \n876838      1  0.996783   11.029596  0.850793   11.029596   \n876839      1  0.996783   13.493770  0.850793   13.493770   \n876840      1  0.996783   25.210603  0.850793   25.210603   \n\n                     file_id  \n0       EPA1200~PA104240.csv  \n1       EPA1200~PA104240.csv  \n2       EPA1200~PA104240.csv  \n3       EPA1200~PA104240.csv  \n4       EPA1200~PA104240.csv  \n...                      ...  \n876836     EPA949~PA5276.csv  \n876837     EPA949~PA5276.csv  \n876838     EPA949~PA5276.csv  \n876839     EPA949~PA5276.csv  \n876840     EPA949~PA5276.csv  \n\n[876841 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>datetime</th>\n      <th>epa_pm25</th>\n      <th>date</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>pm25_cf_1</th>\n      <th>pm25_cf_1_b</th>\n      <th>pm25_cf_1_a</th>\n      <th>year</th>\n      <th>month</th>\n      <th>R2</th>\n      <th>calibrated</th>\n      <th>PearsonR</th>\n      <th>calv2</th>\n      <th>file_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2021-04-15 22:00:00</td>\n      <td>6.0</td>\n      <td>2021-04-15 17:45:56.307692288</td>\n      <td>68.461538</td>\n      <td>26.307692</td>\n      <td>2.379615</td>\n      <td>2.279231</td>\n      <td>2.480000</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>0.999831</td>\n      <td>4.811038</td>\n      <td>0.906382</td>\n      <td>4.811038</td>\n      <td>EPA1200~PA104240.csv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2021-04-15 23:00:00</td>\n      <td>6.0</td>\n      <td>2021-04-15 18:30:48.033333248</td>\n      <td>72.833333</td>\n      <td>25.000000</td>\n      <td>285.067167</td>\n      <td>267.172667</td>\n      <td>302.961667</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>0.999831</td>\n      <td>121.371368</td>\n      <td>0.906382</td>\n      <td>121.371368</td>\n      <td>EPA1200~PA104240.csv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021-04-16 00:00:00</td>\n      <td>6.0</td>\n      <td>2021-04-15 19:30:48.700000000</td>\n      <td>74.000000</td>\n      <td>25.666667</td>\n      <td>113.413167</td>\n      <td>107.516667</td>\n      <td>119.309667</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>0.999831</td>\n      <td>63.850879</td>\n      <td>0.906382</td>\n      <td>63.850879</td>\n      <td>EPA1200~PA104240.csv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021-04-16 01:00:00</td>\n      <td>4.0</td>\n      <td>2021-04-15 20:30:49.033333504</td>\n      <td>74.000000</td>\n      <td>26.000000</td>\n      <td>39.462500</td>\n      <td>37.122000</td>\n      <td>41.803000</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>0.999831</td>\n      <td>26.366329</td>\n      <td>0.906382</td>\n      <td>26.366329</td>\n      <td>EPA1200~PA104240.csv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021-04-16 02:00:00</td>\n      <td>5.0</td>\n      <td>2021-04-15 21:30:50.000000000</td>\n      <td>73.300000</td>\n      <td>25.800000</td>\n      <td>13.508167</td>\n      <td>12.777000</td>\n      <td>14.239333</td>\n      <td>2021</td>\n      <td>4</td>\n      <td>0.999831</td>\n      <td>11.425028</td>\n      <td>0.906382</td>\n      <td>11.425028</td>\n      <td>EPA1200~PA104240.csv</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>876836</th>\n      <td>2022-01-01 03:00:00</td>\n      <td>16.2</td>\n      <td>2021-12-31 22:29:52.900000000</td>\n      <td>57.566667</td>\n      <td>66.766667</td>\n      <td>16.765667</td>\n      <td>15.962667</td>\n      <td>17.568667</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>0.996783</td>\n      <td>12.006813</td>\n      <td>0.850793</td>\n      <td>12.006813</td>\n      <td>EPA949~PA5276.csv</td>\n    </tr>\n    <tr>\n      <th>876837</th>\n      <td>2022-01-01 04:00:00</td>\n      <td>14.6</td>\n      <td>2021-12-31 23:29:53.900000000</td>\n      <td>57.833333</td>\n      <td>65.933333</td>\n      <td>15.928833</td>\n      <td>15.129667</td>\n      <td>16.728000</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>0.996783</td>\n      <td>11.541068</td>\n      <td>0.850793</td>\n      <td>11.541068</td>\n      <td>EPA949~PA5276.csv</td>\n    </tr>\n    <tr>\n      <th>876838</th>\n      <td>2022-01-01 05:00:00</td>\n      <td>14.8</td>\n      <td>2022-01-01 00:29:54.866666752</td>\n      <td>58.666667</td>\n      <td>63.600000</td>\n      <td>14.932833</td>\n      <td>14.095667</td>\n      <td>15.770000</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>0.996783</td>\n      <td>11.029596</td>\n      <td>0.850793</td>\n      <td>11.029596</td>\n      <td>EPA949~PA5276.csv</td>\n    </tr>\n    <tr>\n      <th>876839</th>\n      <td>2022-01-01 06:00:00</td>\n      <td>12.4</td>\n      <td>2022-01-01 01:29:55.800000000</td>\n      <td>59.000000</td>\n      <td>62.000000</td>\n      <td>19.009333</td>\n      <td>18.067333</td>\n      <td>19.951333</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>0.996783</td>\n      <td>13.493770</td>\n      <td>0.850793</td>\n      <td>13.493770</td>\n      <td>EPA949~PA5276.csv</td>\n    </tr>\n    <tr>\n      <th>876840</th>\n      <td>2022-01-01 07:00:00</td>\n      <td>21.0</td>\n      <td>2022-01-01 02:29:56.266666752</td>\n      <td>57.900000</td>\n      <td>64.466667</td>\n      <td>39.604500</td>\n      <td>37.552667</td>\n      <td>41.656333</td>\n      <td>2022</td>\n      <td>1</td>\n      <td>0.996783</td>\n      <td>25.210603</td>\n      <td>0.850793</td>\n      <td>25.210603</td>\n      <td>EPA949~PA5276.csv</td>\n    </tr>\n  </tbody>\n</table>\n<p>876841 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_data_fp = \"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/TrainData/TrainData\"\n",
    "td_files = os.listdir(train_data_fp)\n",
    "\n",
    "x_list = []\n",
    "y_list= []\n",
    "\n",
    "#read in full df for scaling \n",
    "for file in td_files:\n",
    "    i_df = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    i_df['file_id'] = os.path.basename(file)\n",
    "    x_list.append(i_df)  # Append each dataframe to x_list\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "full_df = pd.concat(x_list, ignore_index=True)\n",
    "full_df "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:53.462948Z",
     "start_time": "2024-04-08T21:57:52.072856Z"
    }
   },
   "id": "62d2d8506cfddbbc",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[115], line 52\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m#filter sequences to remove sequences with too many consecutive na values\u001B[39;00m\n\u001B[0;32m     51\u001B[0m max_consec_nas \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m\n\u001B[1;32m---> 52\u001B[0m filtered_index \u001B[38;5;241m=\u001B[39m \u001B[43mfilter_out_nas\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_seq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_consec_nas\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m x_fil \u001B[38;5;241m=\u001B[39m [x_seq[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m filtered_index]\n\u001B[0;32m     54\u001B[0m y_fil \u001B[38;5;241m=\u001B[39m y_seq[filtered_index]\n",
      "Cell \u001B[1;32mIn[113], line 52\u001B[0m, in \u001B[0;36mfilter_out_nas\u001B[1;34m(list_of_dataframes, max_consecutive_nas)\u001B[0m\n\u001B[0;32m     49\u001B[0m indices \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataframe \u001B[38;5;129;01min\u001B[39;00m list_of_dataframes:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;66;03m# Apply the check_condition function to each row in the current dataframe\u001B[39;00m\n\u001B[1;32m---> 52\u001B[0m     condition \u001B[38;5;241m=\u001B[39m \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheck_condition\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;66;03m# Get the indices of rows that meet the condition\u001B[39;00m\n\u001B[0;32m     54\u001B[0m     indices\u001B[38;5;241m.\u001B[39mextend(condition[condition]\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mtolist())\n",
      "File \u001B[1;32m~\\PycharmProjects\\LSTM_python_clean\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:10361\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m  10347\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m  10349\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m  10350\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  10351\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  10359\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m  10360\u001B[0m )\n\u001B[1;32m> 10361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\LSTM_python_clean\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[1;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LSTM_python_clean\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1063\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1065\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n",
      "File \u001B[1;32m~\\PycharmProjects\\LSTM_python_clean\\.venv\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1078\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1079\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m   1080\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m-> 1081\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(v, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m   1082\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m   1083\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m   1085\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[113], line 28\u001B[0m, in \u001B[0;36mfilter_out_nas.<locals>.check_condition\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     26\u001B[0m observed \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mobserved\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m# Identify where NA values are present in the 'observed' column\u001B[39;00m\n\u001B[1;32m---> 28\u001B[0m nas \u001B[38;5;241m=\u001B[39m \u001B[43mobserved\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misna\u001B[49m()\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# Calculate the lengths of consecutive runs of True or False values (NA or not NA)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m count \u001B[38;5;241m=\u001B[39m nas\u001B[38;5;241m.\u001B[39mne(nas\u001B[38;5;241m.\u001B[39mshift())\u001B[38;5;241m.\u001B[39mcumsum()[nas]\u001B[38;5;241m.\u001B[39mvalue_counts()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.float64' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_data_fp = \"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/TrainData/TrainData\"\n",
    "td_files = os.listdir(train_data_fp)\n",
    "\n",
    "x_list = []\n",
    "y_list= []\n",
    "i_list=[]\n",
    "#read in full df for scaling \n",
    "for file in td_files:\n",
    "    i_df = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    i_df['file_id'] = os.path.basename(file)\n",
    "    i_list.append(i_df)  # Append each dataframe to x_list\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "full_df = pd.concat(i_list, ignore_index=True)\n",
    "#create scaler \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(full_df[['pm25_cf_1', 'temperature', 'humidity']])\n",
    "\n",
    "for file in td_files[0:1]:\n",
    "    df_org = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    df_org['file_id'] = os.path.basename(file)\n",
    "    #drop extraneous columns\n",
    "    df = df_org.drop(\n",
    "        columns=['pm25_cf_1_b', 'date', 'pm25_cf_1_a', 'year', 'month', 'R2', 'calibrated', 'PearsonR', 'calv2'])\n",
    "    # Convert the 'datetime_column' to datetime format\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    #sort by date time \n",
    "    df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "    df['observed'] = 1\n",
    "    # Floor and ceiling the 'datetime' column\n",
    "    earliest_date = df['datetime'].min()\n",
    "    latest_date = df['datetime'].max()\n",
    "    #add rows for hours not observed\n",
    "    df = df.set_index('datetime').apply(lambda x: x.reindex(pd.date_range(min(x.index), max(x.index), freq='h')))\n",
    "    #linearlly interpolate across gaps in observations \n",
    "    df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']] = df[\n",
    "        ['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']].apply(lambda group: group.interpolate(method='linear'))\n",
    "    #reset file_id column \n",
    "    df[['file_id']] = file\n",
    "    \n",
    "    #scale input based off range of original  \n",
    "    x = df[['pm25_cf_1', 'temperature', 'humidity', 'observed']]\n",
    "    #x.loc[:, ['pm25_cf_1', 'temperature', 'humidity']] = scaler.transform(x[['pm25_cf_1','temperature','humidity']])\n",
    "    #seperate output \n",
    "    y = df[['epa_pm25']]\n",
    "    time_steps = 24\n",
    "    x_seq, y_seq = create_sequences(x, np.array(y), time_steps)\n",
    "    #filter sequences to remove sequences with too many consecutive na values\n",
    "    max_consec_nas = 3\n",
    "    filtered_index = filter_out_nas(x_seq, max_consec_nas)\n",
    "    x_fil = [x_seq[i] for i in filtered_index]\n",
    "    y_fil = y_seq[filtered_index]\n",
    "    print(file)\n",
    "    \n",
    "    #remove extra columns for X\n",
    "    columns_to_remove = ['observed']\n",
    "    #x_fil = [df.loc[:, df.columns != 'observed'] for df in x_fil]\n",
    "    #x_fil= [df.reset_index(drop=True) for df in x_fil] \n",
    "    \n",
    "    #append to overall list\n",
    "    x_list.extend(x_fil)\n",
    "    y_list.extend(y_fil)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:55.279868Z",
     "start_time": "2024-04-08T21:57:53.463955Z"
    }
   },
   "id": "fc04fdd23be51bcf",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "samp = 0.7\n",
    "index = np.random.choice(len(y_list), int(samp * len(y_list)), replace=False)\n",
    "\n",
    "x_train = [x_list[i] for i in index]\n",
    "y_train = [y_list[i][0] for i in index]\n",
    "x_test = [x_list[i] for i in range(len(y_list)) if i not in index]\n",
    "y_test =[y_list[i][0] for i in range(len(y_list)) if i not in index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:55.280910Z",
     "start_time": "2024-04-08T21:57:55.280910Z"
    }
   },
   "id": "ad5f633042ff5098",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train_array = np.array(x_train)\n",
    "y_train_array = np.array(y_train)\n",
    "x_test_array = np.array(x_test)\n",
    "y_test_array = np.array(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:07:11.179787Z",
     "start_time": "2024-04-08T20:07:03.404062Z"
    }
   },
   "id": "1086d02e4f34d004",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save to numpy arrays\n",
    "np.save(\"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/updt_seq_npy_arrays_70_30_py/x_train.npy\", x_train_array)\n",
    "np.save(\"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/updt_seq_npy_arrays_70_30_py/y_train.npy\", y_train_array)\n",
    "np.save(\"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/updt_seq_npy_arrays_70_30_py/x_test.npy\", x_test_array)\n",
    "np.save(\"C:/Users/ttrefoni/Documents/tt_pm25_tuning/data/updt_seq_npy_arrays_70_30_py/y_test.npy\", y_test_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T20:23:13.486905Z",
     "start_time": "2024-04-08T20:23:13.091485Z"
    }
   },
   "id": "5024be6536379528",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                     pm25_cf_1  temperature   humidity  observed\n2021-07-22 21:00:00   4.592667   116.933333   4.333333       1.0\n2021-07-22 22:00:00   3.895833   118.633333   3.400000       1.0\n2021-07-22 23:00:00   3.490333   117.833333   3.533333       1.0\n2021-07-23 00:00:00   3.873500   114.066667   5.266667       1.0\n2021-07-23 01:00:00   4.154000   109.566667   6.066667       1.0\n2021-07-23 02:00:00   4.854000   105.533333   8.033333       1.0\n2021-07-23 03:00:00   6.474500   101.433333  11.600000       1.0\n2021-07-23 04:00:00   8.505000    96.500000  16.300000       1.0\n2021-07-23 05:00:00   8.126833    93.200000  20.266667       1.0\n2021-07-23 06:00:00   8.215500    89.533333  23.900000       1.0\n2021-07-23 07:00:00   8.956833    85.066667  29.000000       1.0\n2021-07-23 08:00:00   9.113333    82.566667  29.800000       1.0\n2021-07-23 09:00:00   8.860333    81.233333  28.600000       1.0\n2021-07-23 10:00:00   8.728167    79.500000  29.566667       1.0\n2021-07-23 11:00:00   8.970167    77.466667  32.266667       1.0\n2021-07-23 12:00:00   9.265333    75.766667  34.666667       1.0\n2021-07-23 13:00:00   9.130167    74.100000  37.000000       1.0\n2021-07-23 14:00:00   9.379333    73.600000  39.366667       1.0\n2021-07-23 15:00:00  13.338500    79.000000  34.366667       1.0\n2021-07-23 16:00:00  11.574833    87.866667  26.333333       1.0\n2021-07-23 17:00:00  13.437167    95.933333  20.000000       1.0\n2021-07-23 18:00:00   9.821833   103.133333  14.433333       1.0\n2021-07-23 19:00:00   7.718833   109.733333   9.633333       1.0\n2021-07-23 20:00:00   6.733500   114.033333   6.600000       1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pm25_cf_1</th>\n      <th>temperature</th>\n      <th>humidity</th>\n      <th>observed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-07-22 21:00:00</th>\n      <td>4.592667</td>\n      <td>116.933333</td>\n      <td>4.333333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-22 22:00:00</th>\n      <td>3.895833</td>\n      <td>118.633333</td>\n      <td>3.400000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-22 23:00:00</th>\n      <td>3.490333</td>\n      <td>117.833333</td>\n      <td>3.533333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 00:00:00</th>\n      <td>3.873500</td>\n      <td>114.066667</td>\n      <td>5.266667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 01:00:00</th>\n      <td>4.154000</td>\n      <td>109.566667</td>\n      <td>6.066667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 02:00:00</th>\n      <td>4.854000</td>\n      <td>105.533333</td>\n      <td>8.033333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 03:00:00</th>\n      <td>6.474500</td>\n      <td>101.433333</td>\n      <td>11.600000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 04:00:00</th>\n      <td>8.505000</td>\n      <td>96.500000</td>\n      <td>16.300000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 05:00:00</th>\n      <td>8.126833</td>\n      <td>93.200000</td>\n      <td>20.266667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 06:00:00</th>\n      <td>8.215500</td>\n      <td>89.533333</td>\n      <td>23.900000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 07:00:00</th>\n      <td>8.956833</td>\n      <td>85.066667</td>\n      <td>29.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 08:00:00</th>\n      <td>9.113333</td>\n      <td>82.566667</td>\n      <td>29.800000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 09:00:00</th>\n      <td>8.860333</td>\n      <td>81.233333</td>\n      <td>28.600000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 10:00:00</th>\n      <td>8.728167</td>\n      <td>79.500000</td>\n      <td>29.566667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 11:00:00</th>\n      <td>8.970167</td>\n      <td>77.466667</td>\n      <td>32.266667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 12:00:00</th>\n      <td>9.265333</td>\n      <td>75.766667</td>\n      <td>34.666667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 13:00:00</th>\n      <td>9.130167</td>\n      <td>74.100000</td>\n      <td>37.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 14:00:00</th>\n      <td>9.379333</td>\n      <td>73.600000</td>\n      <td>39.366667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 15:00:00</th>\n      <td>13.338500</td>\n      <td>79.000000</td>\n      <td>34.366667</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 16:00:00</th>\n      <td>11.574833</td>\n      <td>87.866667</td>\n      <td>26.333333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 17:00:00</th>\n      <td>13.437167</td>\n      <td>95.933333</td>\n      <td>20.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 18:00:00</th>\n      <td>9.821833</td>\n      <td>103.133333</td>\n      <td>14.433333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 19:00:00</th>\n      <td>7.718833</td>\n      <td>109.733333</td>\n      <td>9.633333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2021-07-23 20:00:00</th>\n      <td>6.733500</td>\n      <td>114.033333</td>\n      <td>6.600000</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list[224]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T21:11:55.916121Z",
     "start_time": "2024-04-08T21:11:55.903906Z"
    }
   },
   "id": "14bbb3f67b5fff4f",
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#drop extraneous columns\n",
    "df = df_org.drop(columns=['pm25_cf_1_b', 'date', 'pm25_cf_1_a', 'year', 'month', 'R2', 'calibrated', 'PearsonR', 'calv2'])\n",
    "# Convert the 'datetime_column' to datetime format\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "df['observed'] = 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2406e3cad94b4f7c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Step 1: Floor and ceiling the 'datetime' column\n",
    "earliest_date = df['datetime'].min()\n",
    "latest_date = df['datetime'].max()\n",
    "\n",
    "df = df.set_index('datetime').apply(lambda x: x.reindex(pd.date_range(min(x.index), max(x.index), freq='h')))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d8cf5ed1ee0ec8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#linearlly interpolate\n",
    "df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']] = df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']].apply(lambda group: group.interpolate(method='linear'))\n",
    "#reset file_id column \n",
    "df[['file_id']]='placeholder'\n",
    "#df[['file_id']]=file"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f4d32f72eaec40",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = df[['pm25_cf_1', 'temperature', 'humidity','observed']]\n",
    "scaler = StandardScaler()\n",
    "x[['pm25_cf_1','temperature','humidity']] = scaler.fit_transform(x[['pm25_cf_1','temperature','humidity']])\n",
    "\n",
    "y = df[['epa_pm25']]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55cac2b4d80d28c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "time_steps = 24\n",
    "x_seq, y_seq = create_sequences(x, np.array(y), time_steps)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ecac5b8e9823f33",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "column_values = [m['observed'] for m in x_seq]\n",
    "column_values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f7e94f61c25db0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def filter_out_nas(list_of_dfs, max_consecutive_nas):\n",
    "    index_fil = []\n",
    "    for i, df in enumerate(list_of_dfs):\n",
    "        observed_column = df['observed']\n",
    "        # Check if there are any NAs at the beginning or end\n",
    "        first_na = observed_column.isna().values[0]\n",
    "        last_na = observed_column.isna().values[-1]\n",
    "        # Check if the number of consecutive NAs is within the threshold\n",
    "        num_consecutive_nas = np.sum(pd.isna(observed_column))\n",
    "        if num_consecutive_nas <= max_consecutive_nas and not first_na and not last_na:\n",
    "            index_fil.append(i)\n",
    "    return index_fil"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef59274a58146488",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "max_consec_nas = 3\n",
    "filtered_index = filter_out_nas(x_seq, max_consec_nas)\n",
    "filtered_index[1:10]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41e0f0a1c75335d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_fil = [x_seq[i] for i in filtered_index]\n",
    "y_fil = y_seq[filtered_index]\n",
    "x_fil[230]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "222ce412b84be02a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "samp = 0.7\n",
    "index = np.random.choice(len(y_fil), int(samp * len(y_fil)), replace=False)\n",
    "\n",
    "x_train = [x_fil[i] for i in index]\n",
    "y_train = y_fil[index]\n",
    "x_test = [x_fil[i] for i in range(len(y_fil)) if i not in index]\n",
    "y_test = y_fil[[i for i in range(len(y_fil)) if i not in index]]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45ab09e7771b7a60"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T19:58:24.900684Z",
     "start_time": "2024-04-08T19:58:24.820297Z"
    }
   },
   "id": "cbdefa49c50516a9",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7dcf785a5294fc71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
