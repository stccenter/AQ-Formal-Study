{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T19:53:11.197003Z",
     "start_time": "2024-04-08T19:52:58.370204Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "\n",
    "TRAIN_DATA_DIRECTORY = 'path/to/your/train/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adc08dff69eba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:50.290877Z",
     "start_time": "2024-04-08T21:57:50.285744Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_sequences(X, y, time_steps=24):\n",
    "    seq_indices = np.arange(0, X.shape[0] - time_steps + 1)\n",
    "    xs = [X[i:i+time_steps] for i in seq_indices]\n",
    "    ys = y[time_steps - 1:]\n",
    "    return xs, ys\n",
    "\n",
    "#this function won't work quite right--I think it checks the overall number of nas \n",
    "def filter_out_nas(list_of_dfs, max_consecutive_nas):\n",
    "    index_fil = []\n",
    "    for i, df in enumerate(list_of_dfs):\n",
    "        observed_column = df['observed']\n",
    "        # Check if there are any NAs at the beginning or end\n",
    "        first_na = observed_column.isna().values[0]\n",
    "        last_na = observed_column.isna().values[-1]\n",
    "        # Check if the number of consecutive NAs is within the threshold\n",
    "        num_consecutive_nas = np.sum(pd.isna(observed_column))\n",
    "        # use run length  \n",
    "        if num_consecutive_nas <= max_consecutive_nas and not first_na and not last_na:\n",
    "            index_fil.append(i)\n",
    "    return index_fil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2d8506cfddbbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:53.462948Z",
     "start_time": "2024-04-08T21:57:52.072856Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_data_fp = TRAIN_DATA_DIRECTORY\n",
    "td_files = os.listdir(train_data_fp)\n",
    "\n",
    "x_list = []\n",
    "y_list= []\n",
    "\n",
    "#read in full df for scaling \n",
    "for file in td_files:\n",
    "    i_df = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    i_df['file_id'] = os.path.basename(file)\n",
    "    x_list.append(i_df)  # Append each dataframe to x_list\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "full_df = pd.concat(x_list, ignore_index=True)\n",
    "full_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc04fdd23be51bcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:55.279868Z",
     "start_time": "2024-04-08T21:57:53.463955Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_data_fp = TRAIN_DATA_DIRECTORY\n",
    "td_files = os.listdir(train_data_fp)\n",
    "\n",
    "x_list = []\n",
    "y_list= []\n",
    "i_list=[]\n",
    "#read in full df for scaling \n",
    "for file in td_files:\n",
    "    i_df = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    i_df['file_id'] = os.path.basename(file)\n",
    "    i_list.append(i_df)  # Append each dataframe to x_list\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "full_df = pd.concat(i_list, ignore_index=True)\n",
    "#create scaler \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(full_df[['pm25_cf_1', 'temperature', 'humidity']])\n",
    "\n",
    "for file in td_files[0:1]:\n",
    "    df_org = pd.read_csv(os.path.join(train_data_fp, file))\n",
    "    df_org['file_id'] = os.path.basename(file)\n",
    "    #drop extraneous columns\n",
    "    df = df_org.drop(\n",
    "        columns=['pm25_cf_1_b', 'date', 'pm25_cf_1_a', 'year', 'month', 'R2', 'calibrated', 'PearsonR', 'calv2'])\n",
    "    # Convert the 'datetime_column' to datetime format\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    #sort by date time \n",
    "    df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "    df['observed'] = 1\n",
    "    # Floor and ceiling the 'datetime' column\n",
    "    earliest_date = df['datetime'].min()\n",
    "    latest_date = df['datetime'].max()\n",
    "    #add rows for hours not observed\n",
    "    df = df.set_index('datetime').apply(lambda x: x.reindex(pd.date_range(min(x.index), max(x.index), freq='h')))\n",
    "    #linearlly interpolate across gaps in observations \n",
    "    df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']] = df[\n",
    "        ['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']].apply(lambda group: group.interpolate(method='linear'))\n",
    "    #reset file_id column \n",
    "    df[['file_id']] = file\n",
    "    \n",
    "    #scale input based off range of original  \n",
    "    x = df[['pm25_cf_1', 'temperature', 'humidity', 'observed']]\n",
    "    #x.loc[:, ['pm25_cf_1', 'temperature', 'humidity']] = scaler.transform(x[['pm25_cf_1','temperature','humidity']])\n",
    "    #seperate output \n",
    "    y = df[['epa_pm25']]\n",
    "    time_steps = 24\n",
    "    x_seq, y_seq = create_sequences(x, np.array(y), time_steps)\n",
    "    #filter sequences to remove sequences with too many consecutive na values\n",
    "    max_consec_nas = 3\n",
    "    filtered_index = filter_out_nas(x_seq, max_consec_nas)\n",
    "    x_fil = [x_seq[i] for i in filtered_index]\n",
    "    y_fil = y_seq[filtered_index]\n",
    "    print(file)\n",
    "    \n",
    "    #remove extra columns for X\n",
    "    columns_to_remove = ['observed']\n",
    "    #x_fil = [df.loc[:, df.columns != 'observed'] for df in x_fil]\n",
    "    #x_fil= [df.reset_index(drop=True) for df in x_fil] \n",
    "    \n",
    "    #append to overall list\n",
    "    x_list.extend(x_fil)\n",
    "    y_list.extend(y_fil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f633042ff5098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:57:55.280910Z",
     "start_time": "2024-04-08T21:57:55.280910Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "samp = 0.7\n",
    "index = np.random.choice(len(y_list), int(samp * len(y_list)), replace=False)\n",
    "\n",
    "x_train = [x_list[i] for i in index]\n",
    "y_train = [y_list[i][0] for i in index]\n",
    "x_test = [x_list[i] for i in range(len(y_list)) if i not in index]\n",
    "y_test =[y_list[i][0] for i in range(len(y_list)) if i not in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086d02e4f34d004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T20:07:11.179787Z",
     "start_time": "2024-04-08T20:07:03.404062Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_array = np.array(x_train)\n",
    "y_train_array = np.array(y_train)\n",
    "x_test_array = np.array(x_test)\n",
    "y_test_array = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024be6536379528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T20:23:13.486905Z",
     "start_time": "2024-04-08T20:23:13.091485Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save to numpy arrays\n",
    "np.save(f\"{TRAIN_DATA_DIRECTORY}/Processed_TF_LSTM/x_train.npy\", x_train_array)\n",
    "np.save(f\"{TRAIN_DATA_DIRECTORY}/Processed_TF_LSTM/y_train.npy\", y_train_array)\n",
    "np.save(f\"{TRAIN_DATA_DIRECTORY}/Processed_TF_LSTM/x_test.npy\", x_test_array)\n",
    "np.save(f\"{TRAIN_DATA_DIRECTORY}/Processed_TF_LSTM/y_test.npy\", y_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbb3f67b5fff4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T21:11:55.916121Z",
     "start_time": "2024-04-08T21:11:55.903906Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_list[224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406e3cad94b4f7c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#drop extraneous columns\n",
    "df = df_org.drop(columns=['pm25_cf_1_b', 'date', 'pm25_cf_1_a', 'year', 'month', 'R2', 'calibrated', 'PearsonR', 'calv2'])\n",
    "# Convert the 'datetime_column' to datetime format\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df = df.sort_values(by='datetime').reset_index(drop=True)\n",
    "df['observed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8cf5ed1ee0ec8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: Floor and ceiling the 'datetime' column\n",
    "earliest_date = df['datetime'].min()\n",
    "latest_date = df['datetime'].max()\n",
    "\n",
    "df = df.set_index('datetime').apply(lambda x: x.reindex(pd.date_range(min(x.index), max(x.index), freq='h')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4d32f72eaec40",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#linearlly interpolate\n",
    "df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']] = df[['epa_pm25', 'temperature', 'humidity', 'pm25_cf_1']].apply(lambda group: group.interpolate(method='linear'))\n",
    "#reset file_id column \n",
    "df[['file_id']]='placeholder'\n",
    "#df[['file_id']]=file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cac2b4d80d28c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = df[['pm25_cf_1', 'temperature', 'humidity','observed']]\n",
    "scaler = StandardScaler()\n",
    "x[['pm25_cf_1','temperature','humidity']] = scaler.fit_transform(x[['pm25_cf_1','temperature','humidity']])\n",
    "\n",
    "y = df[['epa_pm25']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecac5b8e9823f33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_steps = 24\n",
    "x_seq, y_seq = create_sequences(x, np.array(y), time_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e94f61c25db0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_values = [m['observed'] for m in x_seq]\n",
    "column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59274a58146488",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def filter_out_nas(list_of_dfs, max_consecutive_nas):\n",
    "    index_fil = []\n",
    "    for i, df in enumerate(list_of_dfs):\n",
    "        observed_column = df['observed']\n",
    "        # Check if there are any NAs at the beginning or end\n",
    "        first_na = observed_column.isna().values[0]\n",
    "        last_na = observed_column.isna().values[-1]\n",
    "        # Check if the number of consecutive NAs is within the threshold\n",
    "        num_consecutive_nas = np.sum(pd.isna(observed_column))\n",
    "        if num_consecutive_nas <= max_consecutive_nas and not first_na and not last_na:\n",
    "            index_fil.append(i)\n",
    "    return index_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0f0a1c75335d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_consec_nas = 3\n",
    "filtered_index = filter_out_nas(x_seq, max_consec_nas)\n",
    "filtered_index[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222ce412b84be02a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_fil = [x_seq[i] for i in filtered_index]\n",
    "y_fil = y_seq[filtered_index]\n",
    "x_fil[230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab09e7771b7a60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "samp = 0.7\n",
    "index = np.random.choice(len(y_fil), int(samp * len(y_fil)), replace=False)\n",
    "\n",
    "x_train = [x_fil[i] for i in index]\n",
    "y_train = y_fil[index]\n",
    "x_test = [x_fil[i] for i in range(len(y_fil)) if i not in index]\n",
    "y_test = y_fil[[i for i in range(len(y_fil)) if i not in index]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
